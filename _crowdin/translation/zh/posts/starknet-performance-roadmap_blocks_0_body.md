### TL;DR

* 有效性汇总不像 L1 那样受到吞吐量限制。 这可能会在 L2 有效性汇总上带来更高的 TPS。
* Starknet 性能路线图解决了系统中的一个关键元素：定序器。
* 我们在此介绍性能改进的路线图：\
  — Sequencer 并行化\
  — Cairo VM 的新 Rust 实现\
  — 在 Rust 中重新实现 Sequencer\
* 证明者虽然经过了战斗考验，但并不是瓶颈，并且可以处理比现在更多的事情！

### 介绍

Starknet 大约一年前在主网上推出。 我们开始构建 Starknet 时注重功能性。 现在，我们将重点转向通过一系列步骤提高性能，这将有助于增强 Starknet 体验。

在这篇文章中，我们解释了为什么存在仅适用于有效性汇总的广泛优化，并且我们将分享我们在 Starknet 上实施这些步骤的计划。 其中一些步骤已经在 Starknet Alpha 0.10.2 中实现，该版本于 11 月 16 日在测试网上发布，并于昨天在主网上发布。 但在讨论解决方案之前，让我们回顾一下局限性及其原因。

### 块限制：有效性汇总与 L1

提高区块链可扩展性和提高 TPS 的一个潜在方法是解除区块限制（在 Gas/大小方面），同时保持区块时间恒定。 这需要区块生产者（L1 上的验证器、L2 上的排序器）付出更多努力，因此需要更有效地实现这些组件。 为此，我们现在将重点转移到 Starknet 测序仪优化，我们将在以下部分中更详细地描述。

这里自然会出现一个问题。 为什么排序器优化仅限于有效性汇总，也就是说，为什么我们不能在 L1 上实现相同的改进并完全避免有效性汇总的复杂性？ 在下一节中，我们声称两者之间存在根本区别，允许对 L2 进行广泛的优化，而这些优化不适用于 L1。

### 为什么 L1 吞吐量受到限制？

不幸的是，解除 L1 上的块限制存在一个重大缺陷。 通过提高链的增长率，我们还增加了试图跟上最新状态的全节点的需求。 由于L1全节点必须重新执行所有历史记录，块大小的大幅增加（就gas而言）给它们带来了巨大的压力，再次导致较弱的机器退出系统并失去运行全节点的能力只针对足够大的实体。 因此，用户将无法自行验证状态并以不可信的方式参与网络。

这让我们认识到，为了维持一个真正去中心化和安全的系统，L1 吞吐量应该受到限制。

### 为什么相同的障碍不会影响有效性汇总？

只有从全节点的角度考虑，我们才能看到有效性汇总提供的真正威力。 L1全节点需要重新执行整个历史记录以确保当前状态的正确性。 Starknet节点只需要验证STARK证明，并且这种验证所需的计算资源量呈指数级降低。 特别是，从头开始同步不一定涉及执行；节点可以从其对等方接收当前状态的转储，并且仅通过 STARK 证明来验证该状态是否有效。 这使我们能够在不增加全节点要求的情况下增加网络的吞吐量。

因此，我们得出的结论是，L2 定序器需要进行 L1 上不可能实现的一系列优化。

### 未来的性能路线图

在接下来的部分中，我们将讨论目前计划用于 Starknet 测序仪的哪些内容。

### 定序器并行化

我们路线图的第一步是在事务执行中引入并行化。 这是在 Starknet alpha 0.10.2 中引入的，该版本于昨天在主网上发布。 我们现在深入探讨什么是并行化（这是半技术部分，要继续路线图，请跳到下一部分）。

那么“事务并行化”是什么意思呢？ 天真的，并行执行一个事务块是不可能的，因为不同的事务可能是相互依赖的。 下面的示例对此进行了说明。 考虑一个包含来自同一用户的三笔交易的块：

* 交易A：将USDC兑换成ETH
* 交易B：支付ETH购买NFT
* 交易C：USDT兑换BTC

显然，Tx A 必须在 Tx B 之前发生，但 Tx C 完全独立于两者，并且可以并行执行。 如果每笔交易需要1秒执行，那么通过引入并行化，出块时间可以从3秒减少到2秒。

问题的关键在于我们事先不知道事务的依赖关系。 实际上，只有当我们执行示例中的事务 B 时，我们才会看到它依赖于事务 A 所做的更改。更正式地说，这种依赖关系源于事务 B 从事务 A 写入的存储单元中读取的事实。 我们可以将事务视为形成一个依赖图，其中从事务 A 到事务 B 存在一条边，前提是 A 写入的存储单元被 B 读取，因此必须在 B 之前执行。下图显示了一个这种依赖图的示例：

![](https://lh5.googleusercontent.com/OXpkhtGdVlJsLZ9fkz4bFdTIqkOyvGYDaqP3mz_XZSPmPtqy7uZFwlOIHy8e3E4N4rGEPBj0kBpYTsXfIS7q3WURb6kO7HIIZ9cWHaADaPVZoCTdUEQ-uBDLz8e2so0smCleiJRZyZqVLaDVGX3aiJo)

在上面的示例中，每一列都可以并行执行，这是最佳安排（天真地，我们会顺序执行事务 1-9）。

为了克服依赖图事先未知的事实，我们本着 Aptos Labs 开发的 [BLOCK-STM](https://malkhi.com/posts/2022/04/block-stm/) 的精神，向 Starknet 定序器引入了乐观并行化。 在这种范式下，我们乐观地尝试并行运行事务并在发现冲突时重新执行。 例如，我们可能并行执行图 1 中的事务 1-4，却发现 Tx4 依赖于 Tx1。 因此，它的执行是无用的（我们相对于运行 Tx1 的相同状态来运行它，而我们应该针对应用 Tx1 所产生的状态来运行它）。 在这种情况下，我们将重新执行Tx4。

请注意，我们可以在乐观并行化之上添加许多优化。 例如，我们可以在发现使执行无效的依赖项时立即中止执行，而不是天真地等待每个执行结束。

另一个例子是优化重新执行哪些事务的选择。 假设由图 1 中的所有交易组成的块被输入到具有五个 CPU 核心的定序器中。 首先，我们尝试并行执行事务 1-5。 如果完成的顺序是Tx2、Tx3、Tx4、Tx1、最后是Tx5，那么只有在Tx4已经执行完之后我们才会发现依赖关系Tx1→Tx4——这表明它应该被重新执行。 天真地，我们可能也想重新执行 Tx5，因为在新执行 Tx4 的情况下，它的行为可能会有所不同。 然而，我们不只是重新执行现在失效的Tx4之后的所有交易，而是可以遍历由已经终止执行的交易构建的依赖图，并且只重新执行依赖于Tx4的交易。

### Cairo-VM 的新 Rust 实现

Starknet 中的智能合约是在 Cairo 中编写的，并在 Cairo-VM 内执行，该规范出现在 [Cairo 论文](https://eprint.iacr.org/2021/1063.pdf)中。 目前，排序器正在使用 Cairo-VM 的 [python 实现](https://github.com/starkware-libs/cairo-lang/tree/master/src/starkware/cairo/lang/vm)。 为了优化 VM 实现性能，我们发起了用 Rust 重写 VM 的工作。 感谢 [Lambdaclass](https://lambdaclass.com/)的出色工作，他们现在已成为 Starknet 生态系统中的宝贵团队，这项努力很快就会取得成果。

VM 的 Rust 实现 [cairo-rs](https://github.com/lambdaclass/cairo-rs)现在可以执行本机 Cairo 代码。 下一步是处理智能合约的执行以及与 pythonic 序列器的集成。 一旦与 cairo-rs 集成，测序仪的性能预计将显着提高。

### Rust 中的排序器重新实现

我们从 python 转向 Rust 以提高性能并不仅限于 Cairo VM。 除了上面提到的改进之外，我们还计划用 Rust 从头开始重写音序器。 除了 Rust 的内部优势之外，这还为排序器提供了其他优化的机会。 列出几个，我们可以享受 cairo-rs 的好处，而无需 python-rust 通信的开销，并且我们可以完全重新设计状态存储和访问的方式（今天基于 [Patricia-Trie 结构](https://docs.starknet.io/documentation/develop/State/starknet-state/#state_commitment)）。

### 那么证明者呢？

在这篇文章中，我们没有提到有效性汇总中可能最著名的元素——证明者。 人们可以想象，作为架构中可以说是最复杂的组件，它应该是瓶颈，因此也是优化的重点。 有趣的是，现在 Starknet 的瓶颈是更“标准”的组件。 如今，特别是使用 [递归证明](https://medium.com/starkware/recursive-starks-78f8dd401025)，我们可以将比测试网/主网上当前流量更多的交易放入证明中。 事实上，如今，Starknet 区块与 StarkEx 交易一起得到了证明，后者有时会产生数十万个 NFT 铸币。

### 概括

并行化、Rust 等等 — 为即将推出的 Starknet 版本中改进的 TPS 做好准备。